{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "from src.preprocess import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['bibcode', 'label_studio_id', 'ner_ids', 'ner_tags', 'section', 'tokens', 'unique_id'],\n",
       "        num_rows: 1753\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['bibcode', 'label_studio_id', 'ner_ids', 'ner_tags', 'section', 'tokens', 'unique_id'],\n",
       "        num_rows: 1366\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['bibcode', 'label_studio_id', 'ner_ids', 'ner_tags', 'section', 'tokens', 'unique_id'],\n",
       "        num_rows: 2505\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dataset = load_dataset(\"adsabs/WIESP2022-NER\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbiased Domain Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess tags\n",
    "processed_tags, ner_tokens, text = process_entity_tag(data=dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Organization',\n",
       " 'Observatory',\n",
       " 'CelestialObject',\n",
       " 'Event',\n",
       " 'CelestialRegion',\n",
       " 'Identifier']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target entity\n",
    "entity_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-Organization',\n",
       " 'B-Observatory',\n",
       " 'B-CelestialObject',\n",
       " 'B-Event',\n",
       " 'B-CelestialRegion',\n",
       " 'B-Identifier',\n",
       " 'I-Organization',\n",
       " 'I-Observatory',\n",
       " 'I-CelestialObject',\n",
       " 'I-Event',\n",
       " 'I-CelestialRegion',\n",
       " 'I-Identifier']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taget ner_tags\n",
    "ner_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High frequency sub-token\n",
    "\n",
    "for each entity we will generate a list of high frequency subtokens containing:\n",
    "- top 50 3-grams\n",
    "- top 50 5-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_tokens = {}\n",
    "\n",
    "for entity in entity_name:\n",
    "    for bi in [\"B\",\"I\"]:\n",
    "        for n in [3, 5]:\n",
    "            tokens = ner_tokens[f\"{bi}-{entity}\"]\n",
    "            sub_tokens[f\"{bi}-{entity}_{n}_grams\"] =[i[0] for i in find_frequent_subword(tokens, n_gram=n, top=50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organization:\n",
    "+ Start with capital letters\n",
    "+ Name / Country / Org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 1202),\n",
       " ('National', 591),\n",
       " ('Science', 557),\n",
       " ('University', 524),\n",
       " ('Research', 460),\n",
       " ('and', 452),\n",
       " ('for', 382),\n",
       " ('Institute', 320),\n",
       " ('de', 311),\n",
       " ('Space', 277),\n",
       " ('Foundation', 266),\n",
       " ('NASA', 253),\n",
       " ('Council', 252),\n",
       " ('University,', 229),\n",
       " ('NSF', 137),\n",
       " ('European', 129),\n",
       " ('Aeronautics', 115),\n",
       " ('Technology', 114),\n",
       " ('Laboratory,', 112),\n",
       " ('Center', 102),\n",
       " ('Astronomy', 102),\n",
       " ('Centre', 101),\n",
       " ('Ministry', 98),\n",
       " ('Foundation,', 97),\n",
       " ('California', 95),\n",
       " ('State', 92),\n",
       " ('Department', 90),\n",
       " ('the', 84),\n",
       " ('Universities', 82),\n",
       " ('STFC', 82),\n",
       " ('Technology,', 81),\n",
       " ('in', 80),\n",
       " ('Physics', 78),\n",
       " ('Foundation.', 77),\n",
       " ('Office', 75),\n",
       " ('Astrophysics', 72),\n",
       " ('Propulsion', 71),\n",
       " ('Energy', 71),\n",
       " ('Jet', 70),\n",
       " ('Association', 66),\n",
       " ('Australian', 65),\n",
       " ('Telescope', 65),\n",
       " ('Astronomy,', 65),\n",
       " ('University.', 61),\n",
       " ('Natural', 59),\n",
       " ('Administration.', 58),\n",
       " ('Facilities', 56),\n",
       " ('Data', 55),\n",
       " ('Max', 53),\n",
       " ('Academy', 53),\n",
       " ('Planck', 53),\n",
       " ('Sciences', 51),\n",
       " ('China', 48),\n",
       " ('Institute,', 48),\n",
       " ('Inc.,', 48),\n",
       " ('für', 48),\n",
       " ('Agency', 47),\n",
       " ('at', 46),\n",
       " ('Administration', 46),\n",
       " ('la', 45),\n",
       " ('e', 45),\n",
       " ('New', 43),\n",
       " ('ERC', 41),\n",
       " ('Deutsche', 40),\n",
       " ('Education', 39),\n",
       " ('Astrophysics,', 39),\n",
       " ('ESA', 38),\n",
       " ('Alfred', 38),\n",
       " ('Associated', 38),\n",
       " ('P.', 38),\n",
       " ('Sloan', 38),\n",
       " ('Instituto', 37),\n",
       " ('Institut', 37),\n",
       " ('Inc.', 36),\n",
       " ('Processing', 36),\n",
       " ('Nacional', 36),\n",
       " ('NASA.', 35),\n",
       " ('Ohio', 35),\n",
       " ('y', 35),\n",
       " ('Kavli', 34),\n",
       " ('Physics,', 34),\n",
       " ('Analysis', 34),\n",
       " ('The', 32),\n",
       " ('Forschungsgemeinschaft', 32),\n",
       " ('Recherche', 32),\n",
       " ('Chinese', 31),\n",
       " ('CDS,', 30),\n",
       " ('Government', 30),\n",
       " ('Excellence', 30),\n",
       " ('Swedish', 29),\n",
       " ('Scientific', 29),\n",
       " ('Berkeley', 29),\n",
       " ('Princeton', 28),\n",
       " ('Society', 28),\n",
       " ('Lawrence', 27),\n",
       " ('Los', 27),\n",
       " ('Johns', 26),\n",
       " ('Hopkins', 26),\n",
       " ('Portsmouth,', 26),\n",
       " ('Universities,', 26)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity = 'Organization'\n",
    "word_counts = Counter(ner_tokens[f\"B-{entity}\"] + ner_tokens[f\"I-{entity}\"])\n",
    "top_word = word_counts.most_common(100)\n",
    "top_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observatory:\n",
    "+ Contain 'Observatory'\n",
    "+ Location\n",
    "+ All alphabet chars are uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Observatory', 184),\n",
       " ('Observatory,', 93),\n",
       " ('National', 90),\n",
       " ('ALMA', 79),\n",
       " ('Astronomical', 56),\n",
       " ('ESO', 50),\n",
       " ('Astronomy', 48),\n",
       " ('Radio', 36),\n",
       " ('de', 35),\n",
       " ('of', 31),\n",
       " ('Astrophysical', 29),\n",
       " ('Swift', 27),\n",
       " ('Observatory.', 27),\n",
       " ('Smithsonian', 24),\n",
       " ('SDO', 24),\n",
       " ('Keck', 23),\n",
       " ('Fermi', 20),\n",
       " ('Observatorio', 20),\n",
       " ('ESO,', 19),\n",
       " ('Optical', 19),\n",
       " ('Paranal', 18),\n",
       " ('del', 18),\n",
       " ('NAOJ.', 17),\n",
       " ('La', 17),\n",
       " ('Joint', 16),\n",
       " ('Roque', 16),\n",
       " ('los', 16),\n",
       " ('Muchachos', 16),\n",
       " ('Silla', 15),\n",
       " ('Observatoire', 12),\n",
       " ('Cerro', 12),\n",
       " ('Solar', 12),\n",
       " ('W.', 11),\n",
       " ('M.', 11),\n",
       " ('Cumbres', 11),\n",
       " ('European', 10),\n",
       " ('Tololo', 10),\n",
       " ('Inter-American', 10),\n",
       " ('Gemini', 9),\n",
       " ('Southern', 9),\n",
       " ('Japan.', 9),\n",
       " ('East', 8),\n",
       " ('di', 8),\n",
       " ('(Las', 8),\n",
       " ('Asian', 8),\n",
       " ('United', 7),\n",
       " ('Arecibo', 7),\n",
       " ('States', 7),\n",
       " ('Naval', 7),\n",
       " ('Observatories', 7),\n",
       " ('South', 6),\n",
       " ('Shanghai', 6),\n",
       " ('Las', 6),\n",
       " ('African', 6),\n",
       " ('China,', 6),\n",
       " ('Japan,', 6),\n",
       " ('Osservatorio', 5),\n",
       " ('W.M.', 5),\n",
       " ('Observatories,', 5),\n",
       " ('ALMA,', 4),\n",
       " ('Observatário', 4),\n",
       " ('NAOJ', 4),\n",
       " ('ESO.', 4),\n",
       " ('Onsala', 4),\n",
       " ('Lick', 4),\n",
       " ('NANOGrav', 4),\n",
       " ('Paris', 4),\n",
       " ('ALMA.', 4),\n",
       " ('Astronomico', 4),\n",
       " ('Nacional/MCTI,', 4),\n",
       " ('Telescope', 4),\n",
       " ('Space', 4),\n",
       " ('Astronómico', 4),\n",
       " ('NAOC', 3),\n",
       " ('Murchison', 3),\n",
       " ('STEREO', 3),\n",
       " ('Nobeyama', 3),\n",
       " ('Hinode', 3),\n",
       " ('CTIO', 3),\n",
       " ('SAO', 3),\n",
       " ('Apache', 3),\n",
       " ('the', 3),\n",
       " ('INAF', 3),\n",
       " ('Rozhen', 3),\n",
       " ('Siding', 3),\n",
       " ('LCOGT', 3),\n",
       " ('Radio-astronomy', 3),\n",
       " ('Padova', 3),\n",
       " ('Campanas', 3),\n",
       " ('College', 3),\n",
       " ('la', 3),\n",
       " ('Côte', 3),\n",
       " ('Point', 3),\n",
       " ('Dynamics', 3),\n",
       " ('Global', 3),\n",
       " ('Network', 3),\n",
       " ('Observatory);', 3),\n",
       " ('Spring', 3),\n",
       " ('Nacional', 3),\n",
       " ('Lowell', 2)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity = 'Observatory'\n",
    "word_counts = Counter(ner_tokens[f\"B-{entity}\"] + ner_tokens[f\"I-{entity}\"])\n",
    "top_word = word_counts.most_common(100)\n",
    "top_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex['contain_obs'] = r\"observatory|Observatory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CelestialObject:\n",
    "+ Contain 'Sun', 'Earth', 'Gala', 'Milky', 'solar'\n",
    "+ Numbers + capital letters\n",
    "+ All alphabet chars are uppercase\n",
    "+ contain '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NGC', 83),\n",
       " ('HD', 61),\n",
       " ('SN', 43),\n",
       " ('Cyg', 39),\n",
       " ('Galactic', 38),\n",
       " ('solar', 33),\n",
       " ('Sgr', 23),\n",
       " ('Milky', 23),\n",
       " ('GW170817', 20),\n",
       " ('SDSS', 20),\n",
       " ('Tau', 20),\n",
       " ('CMB', 18),\n",
       " ('KIC', 18),\n",
       " ('Leo', 17),\n",
       " ('UGC', 16),\n",
       " ('A', 16),\n",
       " ('ALESS', 16),\n",
       " ('X-1', 16),\n",
       " ('T', 15),\n",
       " ('Way', 15),\n",
       " ('M', 14),\n",
       " ('LMC', 14),\n",
       " ('Orion', 13),\n",
       " ('Sun', 12),\n",
       " ('A*', 12),\n",
       " ('I', 12),\n",
       " ('Upper', 11),\n",
       " ('Tuc', 11),\n",
       " ('Carina', 11),\n",
       " ('α', 11),\n",
       " ('S2', 10),\n",
       " ('PSR', 10),\n",
       " ('MW', 10),\n",
       " ('B', 10),\n",
       " ('SGR', 10),\n",
       " ('GG', 10),\n",
       " ('Local', 9),\n",
       " ('Sun.', 9),\n",
       " ('54', 9),\n",
       " ('Earth', 8),\n",
       " ('Galaxy', 8),\n",
       " ('FSR', 8),\n",
       " ('Solar', 8),\n",
       " ('Sun,', 8),\n",
       " ('B211', 8),\n",
       " ('III', 8),\n",
       " ('OB2', 8),\n",
       " ('122.1', 8),\n",
       " ('3198', 8),\n",
       " ('Cen', 7),\n",
       " ('IRAS', 7),\n",
       " ('UBC', 7),\n",
       " ('A,', 7),\n",
       " ('1H', 7),\n",
       " ('TXS', 7),\n",
       " ('SAX', 7),\n",
       " ('b', 7),\n",
       " ('Dor', 7),\n",
       " ('104', 7),\n",
       " ('Group', 7),\n",
       " ('100546', 7),\n",
       " ('Earth-like', 6),\n",
       " ('Taurus', 6),\n",
       " ('HH', 6),\n",
       " ('Kepler-93b', 6),\n",
       " ('PKS', 6),\n",
       " ('SNR', 6),\n",
       " ('DF', 6),\n",
       " ('1ES', 6),\n",
       " ('iPTF', 6),\n",
       " ('AI', 6),\n",
       " ('MonR2-IRS2', 6),\n",
       " ('Bar', 6),\n",
       " ('Pup', 6),\n",
       " ('T’s', 6),\n",
       " ('4701', 6),\n",
       " ('M33', 5),\n",
       " ('BH', 5),\n",
       " ('Vesta', 5),\n",
       " ('G2', 5),\n",
       " ('IC', 5),\n",
       " ('Cygnus', 5),\n",
       " ('Kapoeta', 5),\n",
       " ('4U', 5),\n",
       " ('G', 5),\n",
       " ('V438', 5),\n",
       " ('A370p_z1', 5),\n",
       " ('Crab', 5),\n",
       " ('Magellanic', 5),\n",
       " ('0519-69.0,', 5),\n",
       " ('V348', 5),\n",
       " ('2008S', 5),\n",
       " ('ε', 5),\n",
       " ('θ', 5),\n",
       " ('47', 5),\n",
       " ('L1506', 5),\n",
       " ('Jovian', 5),\n",
       " ('ID11', 5),\n",
       " ('30', 5),\n",
       " ('CVSO', 5)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity = 'CelestialObject'\n",
    "word_counts = Counter(ner_tokens[f\"B-{entity}\"] + ner_tokens[f\"I-{entity}\"])\n",
    "top_word = word_counts.most_common(100)\n",
    "top_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex['contain_co'] = r\"Sun|Earth|Gala|Milky|solar\"\n",
    "regex['contain_cap_num'] = r\"[A-Z]+\\d+\"\n",
    "\n",
    "sub_tokens['-'] = [\"-\"]\n",
    "sub_tokens['greek_letter'] = ['α', 'ε', 'θ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event:\n",
    "+ Contain year/date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 11),\n",
       " ('in', 6),\n",
       " ('workshop', 5),\n",
       " ('of', 4),\n",
       " ('Program', 3),\n",
       " ('for', 3),\n",
       " ('la', 3),\n",
       " ('the', 3),\n",
       " ('Coronal', 3),\n",
       " ('de', 3),\n",
       " ('Summer', 3),\n",
       " ('Galactic', 2),\n",
       " ('ISIMA', 2),\n",
       " ('“Galactic', 2),\n",
       " ('Kavli', 2),\n",
       " ('Academy', 2),\n",
       " ('Magnetic', 2),\n",
       " ('conference', 2),\n",
       " ('Formation', 2),\n",
       " ('programme', 2),\n",
       " ('Archaeology', 2),\n",
       " ('Precision', 2),\n",
       " ('Stellar', 2),\n",
       " ('Astrophysics”', 2),\n",
       " ('Observations', 2),\n",
       " ('2015', 1),\n",
       " ('Cloud', 1),\n",
       " ('La', 1),\n",
       " ('deep', 1),\n",
       " ('Convocatoria', 1),\n",
       " ('“The', 1),\n",
       " ('“New', 1),\n",
       " ('“Decoding', 1),\n",
       " ('Meteoroid', 1),\n",
       " ('Estrategia', 1),\n",
       " ('supermassive', 1),\n",
       " ('‘Protoplanetary', 1),\n",
       " ('LSST:', 1),\n",
       " ('infrared', 1),\n",
       " ('“Solving', 1),\n",
       " ('ESANN-2018', 1),\n",
       " ('KITP', 1),\n",
       " ('2019', 1),\n",
       " ('‘Gaia', 1),\n",
       " ('Global', 1),\n",
       " ('Physics', 1),\n",
       " ('The', 1),\n",
       " ('2013', 1),\n",
       " ('3rd', 1),\n",
       " ('(International', 1),\n",
       " ('ISIMA,', 1),\n",
       " ('NSF', 1),\n",
       " ('‘The', 1),\n",
       " ('“Sub-arcsec', 1),\n",
       " ('“Implications', 1),\n",
       " ('EUROWD-21', 1),\n",
       " ('Dartmouth', 1),\n",
       " ('Astronomy', 1),\n",
       " ('Foreign', 1),\n",
       " ('Study', 1),\n",
       " ('I', 1),\n",
       " ('2018', 1),\n",
       " ('Serena', 1),\n",
       " ('School', 1),\n",
       " ('Data', 1),\n",
       " ('Science,', 1),\n",
       " ('learning', 1),\n",
       " ('course', 1),\n",
       " ('presentations', 1),\n",
       " ('nacional', 1),\n",
       " ('subvención', 1),\n",
       " ('a', 1),\n",
       " ('instalación', 1),\n",
       " ('en', 1),\n",
       " ('academia,', 1),\n",
       " ('convocatoria', 1),\n",
       " ('2017', 1),\n",
       " ('Obscured', 1),\n",
       " ('Universe:', 1),\n",
       " ('Dust', 1),\n",
       " ('Gas', 1),\n",
       " ('Distant', 1),\n",
       " ('Starburst', 1),\n",
       " ('Galaxies”', 1),\n",
       " ('Frontiers', 1),\n",
       " ('Far-infrared', 1),\n",
       " ('Sub-millimeter', 1),\n",
       " ('Astronomy”', 1),\n",
       " ('Pre-Eruptive', 1),\n",
       " ('Configuration', 1),\n",
       " ('Mass', 1),\n",
       " ('Ejections”', 1),\n",
       " ('2016', 1),\n",
       " ('Sostenibilidad', 1),\n",
       " ('2014-2015', 1),\n",
       " ('Universidad', 1),\n",
       " ('Antioquia', 1),\n",
       " ('black', 1),\n",
       " ('holes', 1),\n",
       " ('June', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity = 'Event'\n",
    "word_counts = Counter(ner_tokens[f\"B-{entity}\"] + ner_tokens[f\"I-{entity}\"])\n",
    "top_word = word_counts.most_common(100)\n",
    "top_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex['contain_year'] = r\"\\d{4}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CelestialRegion\n",
    "- contain '°', '′'\n",
    "- contain '>', '<', '=', '|'\n",
    "- single lower case character (not 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('=', 11),\n",
       " ('Galactic', 10),\n",
       " ('b', 7),\n",
       " ('field', 7),\n",
       " ('extragalactic', 5),\n",
       " ('|', 5),\n",
       " ('BICEP2', 4),\n",
       " ('decl.', 4),\n",
       " ('COSMOS', 3),\n",
       " ('LR', 3),\n",
       " ('Universe', 3),\n",
       " ('l', 3),\n",
       " ('h', 3),\n",
       " ('m', 3),\n",
       " ('local', 2),\n",
       " ('Northern', 2),\n",
       " ('galactic', 2),\n",
       " ('R.A.', 2),\n",
       " ('Planck', 2),\n",
       " ('and', 2),\n",
       " ('longitude', 2),\n",
       " (')', 2),\n",
       " ('plane', 2),\n",
       " ('plane,', 2),\n",
       " ('region', 2),\n",
       " ('(2000)', 2),\n",
       " ('Common', 2),\n",
       " ('Field', 2),\n",
       " ('11', 2),\n",
       " ('54', 2),\n",
       " ('inner', 1),\n",
       " ('170°', 1),\n",
       " ('(', 1),\n",
       " ('(l,', 1),\n",
       " ('WISE', 1),\n",
       " ('Antlia', 1),\n",
       " ('anti-sunward', 1),\n",
       " ('sunward', 1),\n",
       " ('VPOS', 1),\n",
       " ('Boötes', 1),\n",
       " ('TESS', 1),\n",
       " ('CoRoT', 1),\n",
       " ('Cygnus', 1),\n",
       " ('Lyra.', 1),\n",
       " ('HXDF,', 1),\n",
       " ('GOODS-North', 1),\n",
       " ('(LR72).', 1),\n",
       " ('LR33).', 1),\n",
       " ('early', 1),\n",
       " ('“', 1),\n",
       " ('central', 1),\n",
       " ('GSE', 1),\n",
       " ('Geocentric', 1),\n",
       " ('(GSE)', 1),\n",
       " ('303°', 1),\n",
       " ('(R.A.', 1),\n",
       " ('−4.3°', 1),\n",
       " ('−3.3°', 1),\n",
       " ('349.2°,', 1),\n",
       " ('Hemisphere.', 1),\n",
       " ('Galaxy', 1),\n",
       " ('7R.A.', 1),\n",
       " ('175°,', 1),\n",
       " ('−3°', 1),\n",
       " ('3°).', 1),\n",
       " (',', 1),\n",
       " ('(311.627,', 1),\n",
       " ('+0.27).', 1),\n",
       " ('(210.927°,', 1),\n",
       " ('63.280°).', 1),\n",
       " ('Sky', 1),\n",
       " ('bulge', 1),\n",
       " ('halo.', 1),\n",
       " ('(|', 1),\n",
       " ('>', 1),\n",
       " ('10°', 1),\n",
       " ('−10°)', 1),\n",
       " ('(with', 1),\n",
       " ('10°),', 1),\n",
       " ('Gamma-ray', 1),\n",
       " ('Strip', 1),\n",
       " ('coordinates.', 1),\n",
       " ('deep-field', 1),\n",
       " ('observed', 1),\n",
       " ('fields,', 1),\n",
       " ('regions,', 1),\n",
       " ('regions', 1),\n",
       " ('165”', 1),\n",
       " ('southern', 1),\n",
       " ('SDSS', 1),\n",
       " ('footprint,', 1),\n",
       " ('Stripe', 1),\n",
       " ('82', 1),\n",
       " ('5', 1),\n",
       " ('52', 1),\n",
       " ('129;', 1),\n",
       " ('26°59′33′′).', 1),\n",
       " ('Solar', 1),\n",
       " ('Ecliptic', 1),\n",
       " ('latitude', 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity = 'CelestialRegion'\n",
    "word_counts = Counter(ner_tokens[f\"B-{entity}\"] + ner_tokens[f\"I-{entity}\"])\n",
    "top_word = word_counts.most_common(100)\n",
    "top_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_tokens['degree'] = ['°', '′']\n",
    "sub_tokens['operation'] = ['>', '<', '=', '|']\n",
    "regex['hml'] = r\"^[hml]$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifier\n",
    "- start with 'ADS/JAO'\n",
    "- start with / contain '#'\n",
    "- r'/d{4}\\./d{1,2}\\./d{5}'\n",
    "- all numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CBP1', 6),\n",
       " ('CBP2', 4),\n",
       " ('AR', 3),\n",
       " ('ADS/JAO.ALMA#', 3),\n",
       " ('(Version', 3),\n",
       " ('version', 2),\n",
       " ('NOAA', 2),\n",
       " ('CBP1,', 2),\n",
       " ('12290', 2),\n",
       " ('LIGO', 1),\n",
       " ('2016.1.01164.S.', 1),\n",
       " ('(v4.7.2,', 1),\n",
       " ('ADS/JAO.ALMA#2011.0.00876.S,', 1),\n",
       " ('ADS/JAO.ALMA#2012.00650.', 1),\n",
       " ('<inline-formula>', 1),\n",
       " ('V,', 1),\n",
       " ('ADS/JAO.ALMA#2013.1.00111.S.', 1),\n",
       " ('ADS/JAO.ALMA#2011.0.00172.S.', 1),\n",
       " ('24Jun2019_V6.26.1,', 1),\n",
       " ('ADS/JAO.ALMA#2013.1.00798.S.', 1),\n",
       " ('ADS/JAO.ALMA[2013.1.00486.S].', 1),\n",
       " ('ADS/JAO.ALMA#2013.1.00806.S.', 1),\n",
       " ('SOL2014-01-13T21:51M1.3,', 1),\n",
       " ('72877.', 1),\n",
       " ('ADS/JAO.ALMA#2012.1.00978.S.', 1),\n",
       " ('#', 1),\n",
       " ('RP200442)', 1),\n",
       " ('RP200576)', 1),\n",
       " ('HRL0000BABA', 1),\n",
       " ('FRT0000BABA', 1),\n",
       " ('(v8845;', 1),\n",
       " ('(v4.2.2;', 1),\n",
       " ('MJLSG32.', 1),\n",
       " ('#14125.', 1),\n",
       " ('ID', 1),\n",
       " ('#14125,', 1),\n",
       " ('#14125', 1),\n",
       " ('CBP2,', 1),\n",
       " ('(PFL1)', 1),\n",
       " ('PFL1,', 1),\n",
       " ('N03E05', 1),\n",
       " ('N03W18', 1),\n",
       " ('ADS/JAO.ALMA#2013.1.00151.S,', 1),\n",
       " ('ADS/JAO.ALMA#2013.1.00034.S', 1),\n",
       " ('ADS/JAO.ALMA#2012.1.00523.S.', 1),\n",
       " ('IceCube-170922A.', 1),\n",
       " ('v1.4.0', 1),\n",
       " ('GO', 1),\n",
       " ('(GO', 1),\n",
       " ('L091N02,', 1),\n",
       " ('LIGO-P1500117.', 1),\n",
       " ('2013.1.01034.S', 1),\n",
       " ('2012.1.00146.S', 1),\n",
       " ('2013.1.00048.S', 1),\n",
       " ('2012.1.00123.S', 1),\n",
       " ('ADS/JAO.ALMA#2012.1.00453.S.', 1),\n",
       " ('#4092.', 1),\n",
       " ('0822580401,', 1),\n",
       " ('0822580501,', 1),\n",
       " ('AO-17,', 1),\n",
       " ('#82258;', 1),\n",
       " ('90401327002,', 1),\n",
       " ('90401327004,', 1),\n",
       " ('90401327006,', 1),\n",
       " ('90401327008),', 1),\n",
       " ('composite_42_65_1709.dat,', 1),\n",
       " ('GN002.', 1),\n",
       " ('NAC_2014-09-05T06.35.55.557Z_ID30_1397549300_F22.', 1),\n",
       " ('ADS/JAO.ALMA#2011.0.00294.S;', 1),\n",
       " ('#2012.0.00307.S;', 1),\n",
       " ('#2013.1.00118.S;', 1),\n",
       " ('#2012.1.00090.S;', 1),\n",
       " ('#2015.1.01528.S;', 1),\n",
       " ('#2016.1.00434.S;', 1),\n",
       " ('#2017.1.01492.S.', 1),\n",
       " ('95701-01-03-00', 1),\n",
       " ('91701-01-52-01', 1),\n",
       " ('SOL2013-05-13', 1),\n",
       " ('ADS/JAO.ALMA#2017.1.00441.S.', 1),\n",
       " ('Document', 1),\n",
       " ('P1900228.', 1),\n",
       " ('v5.1.1;', 1),\n",
       " ('3.3,', 1),\n",
       " ('<tex-math>', 1),\n",
       " ('</tex-math>', 1),\n",
       " ('<inline-graphic', 1),\n",
       " ('xmlns:xlink=\"http://www.w3.org/1999/xlink\"', 1),\n",
       " ('xlink:href=\"apjaa88acieqn94.gif\"></inline-graphic>', 1),\n",
       " ('</inline-formula>', 1),\n",
       " ('2013.1.00034.S.', 1),\n",
       " ('’20140825’.', 1),\n",
       " ('LA-UR-17-20973.', 1),\n",
       " ('2013.1.01268.S.', 1),\n",
       " ('2013.1.00187.S.', 1),\n",
       " ('12574.', 1),\n",
       " ('C254LA.', 1),\n",
       " ('11029', 1),\n",
       " ('14114.', 1),\n",
       " ('14096)', 1),\n",
       " ('2;', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity = 'Identifier'\n",
    "word_counts = Counter(ner_tokens[f\"B-{entity}\"] + ner_tokens[f\"I-{entity}\"])\n",
    "top_word = word_counts.most_common(100)\n",
    "top_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_tokens['#'] = ['#']\n",
    "\n",
    "regex['ADS/JAO'] = r\"^ADS/JAO\"\n",
    "regex['num_seq'] = r'/d{4}\\./d{1,2}\\./d{5}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "features['sub_tokens'] = sub_tokens\n",
    "features['regex'] = regex\n",
    "\n",
    "with open('unbiased_domain_knowledge.json', 'w') as fp:\n",
    "    json.dump(features, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biased Domain Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# preprocess tags\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m processed_tags, ner_tokens, text \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_entity_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Study/Mcomp/CS5340_Uncertainty_modeling_in_AI/project/CS5340_Bert_CRF/src/preprocess.py:44\u001b[0m, in \u001b[0;36mprocess_entity_tag\u001b[0;34m(data, ner_tags)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ner_copy):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# taget ner\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ner_tags:\n\u001b[0;32m---> 44\u001b[0m         ner_tokens[t]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# redundant ner\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m t \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Study/Mcomp/CS5340_Uncertainty_modeling_in_AI/project/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:2810\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Study/Mcomp/CS5340_Uncertainty_modeling_in_AI/project/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:2795\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2794\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2795\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2797\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/Study/Mcomp/CS5340_Uncertainty_modeling_in_AI/project/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:629\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    627\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/Study/Mcomp/CS5340_Uncertainty_modeling_in_AI/project/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:396\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 396\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m~/Study/Mcomp/CS5340_Uncertainty_modeling_in_AI/project/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:436\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 436\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m~/Study/Mcomp/CS5340_Uncertainty_modeling_in_AI/project/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py:144\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unnest(\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# preprocess tags\n",
    "processed_tags_200, ner_tokens_200, _ = process_entity_tag(data=dataset['train'][:200])\n",
    "processed_tags_500, ner_tokens_500, _ = process_entity_tag(data=dataset['train'][:500])\n",
    "processed_tags_1000, ner_tokens_1000, _ = process_entity_tag(data=dataset['train'][:1000])\n",
    "processed_tags, ner_tokens, _ = process_entity_tag(data=dataset['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High frequency sub-token\n",
    "\n",
    "for each entity we will generate a list of high frequency subtokens containing:\n",
    "- top 50 3-grams\n",
    "- top 50 5-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_tokens = {}\n",
    "processed_tags_list = [processed_tags_200, processed_tags_500, processed_tags_1000]\n",
    "\n",
    "for entity in entity_name:\n",
    "    for bi in [\"B\",\"I\"]:\n",
    "        for n in [3, 5]:\n",
    "            tokens = ner_tokens[f\"{bi}-{entity}\"]\n",
    "            sub_tokens[f\"{bi}-{entity}_{n}_grams\"] =[i[0] for i in find_frequent_subword(tokens, n_gram=n, top=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-TUA0M7_Q-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
