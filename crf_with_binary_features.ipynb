{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pycrfsuite\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "\n",
    "import spacy\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"adsabs/WIESP2022-NER\")\n",
    "train_data = dataset['train']\n",
    "validation_data = dataset['validation']\n",
    "test_data = dataset['test']\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1753\n"
     ]
    }
   ],
   "source": [
    "formatted_data = []\n",
    "for item in dataset['train']:\n",
    "    tokens = item['tokens']\n",
    "    ner_tags = item['ner_tags']\n",
    "    sentence = list(zip(tokens, ner_tags))\n",
    "    formatted_data.append(sentence)\n",
    "print(len(formatted_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spacy_ner(sentence):\n",
    "    doc = nlp(\" \".join(token for token, _ in sentence))\n",
    "    spacy_features = [{} for _ in sentence]  # Initialize empty feature dict for each token\n",
    "\n",
    "    # Match spaCy tokens to the original tokens and assign NER tags\n",
    "    spacy_index = 0\n",
    "    for i, (token, _) in enumerate(sentence):\n",
    "        while spacy_index < len(doc) and doc[spacy_index].idx < len(\" \".join(sentence[i][0] for i in range(0, i + 1))):\n",
    "            if doc[spacy_index].ent_type_:\n",
    "                spacy_features[i]['spacy_ner_' + doc[spacy_index].ent_type_.lower()] = 1\n",
    "            spacy_index += 1\n",
    "\n",
    "    return spacy_features\n",
    "\n",
    "def word2features(sent, i, spacy_features):\n",
    "    word = sent[i][0]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    features.update(spacy_features[i])\n",
    "\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i+1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def prepare_data(sentences):\n",
    "    X = []\n",
    "    y = []\n",
    "    for s in sentences:\n",
    "        spacy_features = add_spacy_ner(s)\n",
    "        X.append([word2features(s, i, spacy_features) for i in range(len(s))])\n",
    "        y.append([label for token, label in s])\n",
    "    return X, y\n",
    "\n",
    "def preprocess_data(dataset):\n",
    "    formatted_data = []\n",
    "    for item in dataset:\n",
    "        tokens = item['tokens']\n",
    "        ner_tags = item['ner_tags']\n",
    "        sentence = list(zip(tokens, ner_tags))\n",
    "        formatted_data.append(sentence)\n",
    "    return formatted_data\n",
    "\n",
    "\n",
    "def process_sentence(sentence):\n",
    "    spacy_features = add_spacy_ner(sentence)\n",
    "    return [word2features(sentence, i, spacy_features) for i in range(len(sentence))], [label for token, label in sentence]\n",
    "\n",
    "def preprocess_data_new(dataset):\n",
    "    formatted_data = [(item['tokens'], item['ner_tags']) for item in dataset]  # Load data\n",
    "\n",
    "    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "        results = pool.map(process_sentence, formatted_data)\n",
    "\n",
    "    X, y = zip(*results)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data(preprocess_data(train_data))\n",
    "X_valid, y_valid = prepare_data(preprocess_data(validation_data))\n",
    "X_test, y_test = prepare_data(preprocess_data(test_data))\n",
    "\n",
    "X_train_75, X_train_25, y_train_75, y_train_25 = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "X_train_50_1, X_train_50_2, y_train_50_1, y_train_50_2 = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "X_train_90, X_train_10, y_train_90, y_train_10 = train_test_split(X_train, y_train, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 4s, sys: 2.44 s, total: 3min 6s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,  # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "trainer.train('ner-model-full-bin.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 1.03 s, total: 1min 31s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(X_train_50_1, y_train_50_1):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,  # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "trainer.train('ner-model-50-bin.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48 s, sys: 738 ms, total: 48.7 s\n",
      "Wall time: 48.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(X_train_25, y_train_25):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,  # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "trainer.train('ner-model-25-bin.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.7 s, sys: 232 ms, total: 15.9 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(X_train_10, y_train_10):\n",
    "    trainer.append(xseq, yseq)\n",
    "\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,  # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,\n",
    "    'feature.possible_transitions': True\n",
    "})\n",
    "trainer.train('ner-model-10-bin.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('ner-model.crfsuite')\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_valid]\n",
    "y_valid_flat = [item for sublist in y_valid for item in sublist]\n",
    "y_pred_flat = [item for sublist in y_pred for item in sublist]\n",
    "\n",
    "result = classification_report(y_valid_flat, y_pred_flat)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('ner-model.crfsuite')\n",
    "y_test_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "y_test_flat = [item for sublist in y_test for item in sublist]\n",
    "y_test_pred_flat = [item for sublist in y_test_pred for item in sublist]\n",
    "\n",
    "result = classification_report(y_test_flat, y_test_pred_flat)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCC and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset\n",
      "f1_score: 0.4846, mcc: 0.8069\n",
      "50% Dataset\n",
      "f1_score: 0.4685, mcc: 0.7931\n",
      "25% Dataset\n",
      "f1_score: 0.4061, mcc: 0.7732\n",
      "10% Dataset\n",
      "f1_score: 0.3306, mcc: 0.7255\n"
     ]
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "\n",
    "# Full\n",
    "print(\"Full Dataset\")\n",
    "tagger.open('ner-model-full-bin.crfsuite')\n",
    "y_test_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "y_test_flat = [item for sublist in y_test for item in sublist]\n",
    "y_test_pred_flat = [item for sublist in y_test_pred for item in sublist]\n",
    "\n",
    "# result = classification_report(y_test_flat, y_test_pred_flat)\n",
    "f1 = f1_score(y_test_flat, y_test_pred_flat, average='macro')\n",
    "mcc = matthews_corrcoef(y_test_flat, y_test_pred_flat)\n",
    "print(f\"f1_score: {f1:.4f}, mcc: {mcc:.4f}\")\n",
    "\n",
    "# 50%\n",
    "print(\"50% Dataset\")\n",
    "tagger.open('ner-model-50-bin.crfsuite')\n",
    "y_test_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "y_test_flat = [item for sublist in y_test for item in sublist]\n",
    "y_test_pred_flat = [item for sublist in y_test_pred for item in sublist]\n",
    "\n",
    "# result = classification_report(y_test_flat, y_test_pred_flat)\n",
    "f1 = f1_score(y_test_flat, y_test_pred_flat, average='macro')\n",
    "mcc = matthews_corrcoef(y_test_flat, y_test_pred_flat)\n",
    "print(f\"f1_score: {f1:.4f}, mcc: {mcc:.4f}\")\n",
    "\n",
    "# 25%\n",
    "print(\"25% Dataset\")\n",
    "tagger.open('ner-model-25-bin.crfsuite')\n",
    "y_test_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "y_test_flat = [item for sublist in y_test for item in sublist]\n",
    "y_test_pred_flat = [item for sublist in y_test_pred for item in sublist]\n",
    "\n",
    "# result = classification_report(y_test_flat, y_test_pred_flat)\n",
    "f1 = f1_score(y_test_flat, y_test_pred_flat, average='macro')\n",
    "mcc = matthews_corrcoef(y_test_flat, y_test_pred_flat)\n",
    "print(f\"f1_score: {f1:.4f}, mcc: {mcc:.4f}\")\n",
    "\n",
    "# 10%\n",
    "print(\"10% Dataset\")\n",
    "tagger.open('ner-model-10-bin.crfsuite')\n",
    "y_test_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "y_test_flat = [item for sublist in y_test for item in sublist]\n",
    "y_test_pred_flat = [item for sublist in y_test_pred for item in sublist]\n",
    "\n",
    "# result = classification_report(y_test_flat, y_test_pred_flat)\n",
    "f1 = f1_score(y_test_flat, y_test_pred_flat, average='macro')\n",
    "mcc = matthews_corrcoef(y_test_flat, y_test_pred_flat)\n",
    "print(f\"f1_score: {f1:.4f}, mcc: {mcc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
